<!DOCTYPE html>

<html lang="en">

<head>
    <title>RoboDrive Challenge</title>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <link href="navbar-top-fixed.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link rel="icon" href="logo.png" type="image/png">

    <link href="jiaun.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet/less" type="text/css" href="styles.less">
    <link href="carousel.css" rel="stylesheet">
    <link href="pricing.css" rel="stylesheet">
    <meta http-equiv="Access-Control-Allow-Origin" content="*">
    <script src="https://cdn.jsdelivr.net/npm/less@4.1.1"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
      <script type="text/javascript">
        // alert(window.location.href);
    var index = "http://seasondepth-challenge.org/index/";
    var index_ = "http://seasondepth-challenge.org/index";
    if ((index == window.location.href) || (index_ == window.location.href))
        window.location.href = "http://seasondepth-challenge.org/";
</script>
    <script>function myFunction()
        {
            confirm("For the evaluation, please send the depth maps as a .zip file to the email (seasondepth@outlook.com) with cc'ing to (hanjianghu@cmu.edu) and (yangbaoquan@sjtu.edu.cn).");
            // alert("你好，我是一个警告框！");
        }</script>
    <style>
        .container1 {
            position: relative;
            width: 100%;
            max-width: 5000px;
        }
        
        .modal-content {
            border: 2px solid rgb(0, 128, 204);
            background-color: rgb(0, 0, 0);
            border-radius: 15px;
        }
        
        .modal-header {
            background-color: rgb(0, 128, 204);
            border: 2px solid rgb(0, 128, 204);
            border-top-left-radius: 10px;
            border-top-right-radius: 10px;
        }
        
        .modal-footer {
            border-top: 0 none;
        }
        
        .container1 img {
            width: 100%;
            height: auto;
        }
        
         :target:before {
            content: "";
            display: block;
            height: 100px;
            margin: -90px 0 0;
        }
        
        .container1 .btn {
            position: absolute;
            top: 75%;
            left: 50%;
            transform: translate(-50%, -50%);
            -ms-transform: translate(-50%, -50%);
            background-color: rgb(0, 128, 204);
            color: white;
            font-size: 20px;
            padding: 18px 280px;
            border: none;
            cursor: pointer;
            border-radius: 6px;
            text-align: center;
        }
        
        .container1 .btn:hover {
            background-color: black;
        }
        
        .mx-a {}
        
        .text-cen {}
        
        .mb-6 {}
    </style>




</head>

<body>
    <div class="modal" id="signup" tabindex="-1" aria-labelledby="signupLabel" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="modal-header">
                    <h4 class="text-black modal-title">Welcome to sign up!</h4>
                    <button type="button" class="btn-close" aria-label="Close" data-bs-dismiss="modal"></button>
                    <!-- <h4 id="myModalLabel" class="text-black modal-title">Sign Up</h4>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button> -->
                </div>
                <div class="modal-body">
                    <form class="form-horizontal">
                        <div class="form-group">
                            <label class="col control-label">User Name</label>
                            <div class="col">
                                <input type="text" name="userName" class="form-control" id="userName_add_input" placeholder="e.g. Alice">
                                <span class="help-block"></span>
                            </div>
                        </div>
                        <div class="form-group">
                            <label class="col control-label">Email</label>
                            <div class="col">
                                <input type="text" name="eMail" class="form-control" id="eMail_add_input" placeholder="e.g. alice@example.com">
                                <span class="help-block"></span>
                            </div>
                        </div>
                        <div class="form-group">
                            <label class="col control-label">Password</label>
                            <div class="col">
                                <input type="password" name="passWord" class="form-control" id="passWord_add_input" placeholder="e.g. 123456">
                                <span class="help-block"></span>
                            </div>
                        </div>
                        <div class="form-group">
                            <label class="col control-label">Confirm Password</label>
                            <div class="col">
                                <input type="password" name="confirmPassword" class="form-control" id="confirmPassword_add_input" placeholder="e.g. 123456">
                                <span class="help-block"></span>
                            </div>
                        </div>
                        <div class="form-group">
                            <label class="col control-label">Verification Code</label>
                            <div class="col">
                                <input type="text" name="verifyCode" class="form-control" id="verify_code_input" placeholder="4-digit code sent to your email address">
                                <span class="help-block"></span>
                            </div>
                        </div>
                    </form>
                </div>
                <!-- <div class="modal-footer">
                    <button type="button" class="btn btn-dark" id="send_code_btn">SendCode</button>
                    <button type="button" class="btn btn-warning" id="user_save_btn">Sign up now</button>
                </div> -->

            </div>
        </div>
    </div>

    <div class="modal" id="login" tabindex="-1" aria-labelledby="loginLabel" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="modal-header">
                    <h4 class="text-black modal-title">Welcome back!</h4>
                    <button type="button" class="btn-close" aria-label="Close" data-bs-dismiss="modal"></button>
                    <!-- <h4 id="myModalLabel" class="text-black modal-title">Sign Up</h4>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button> -->
                </div>
                <div class="modal-body">
                    <form class="form-horizontal">
                        <div class="form-group">
                            <label class="col control-label">User Name</label>
                            <div class="col">
                                <input type="text" name="userName" class="form-control" id="userName_add_input" placeholder="e.g. Alice">
                                <span class="help-block"></span>
                            </div>
                        </div>

                        <div class="form-group">
                            <label class="col control-label">Password</label>
                            <div class="col">
                                <input type="password" name="passWord" class="form-control" id="passWord_add_input" placeholder="e.g. 123456">
                                <span class="help-block"></span>
                            </div>
                        </div>


                    </form>
                </div>
                <div class="modal-footer">
                    <!-- <button type="button" class="btn btn-default" data-dismiss="modal">Close</button> -->
                    <button type="button" class="btn btn-warning" id="user_save_btn">Login</button>
                </div>

            </div>
        </div>
    </div>
    <div class="bg-black">
        <header class="p-3 text-white fixed-top" style="background-color:#252727;">
            <div class="container">
                <div class="d-flex flex-wrap align-items-center">

                    <a href="./index.html"><img src="brand.png" class="navbar-brand" width="50"></a>
                    <ul class="nav col-lg-auto me-lg-auto mb-md-0">
                        <li class="align-content-center nav-item">
                            <a href="#introduction" class="nav-link text-white">
                                <a1>Intro</a1>
                            </a>
                        </li>
                        <li>
                            <a href="#venue" class="nav-link text-white">
                                <a1>Venue</a1>
                            </a>
                        </li>
                        <li>
                            <a href="#toolkit" class="nav-link text-white">
                                <a1>Toolkit</a1>
                            </a>
                        </li>
                        <li>
                            <a href="#tracks" class="nav-link text-white">
                                <a1>Tracks</a1>
                            </a>
                        </li>
                        <li>
                            <a href="#timeline" class="nav-link text-white">
                                <a1>Timeline</a1>
                            </a>
                        </li>
                        <li>
                            <a href="#awards" class="nav-link text-white">
                                <a1>Awards</a1>
                            </a>
                        </li>
                        <li>
                            <a href="#evaluation" class="nav-link text-white">
                                <a1>Evaluation</a1>
                            </a>
                        </li>
                        <li>
                            <a href="#contact" class="nav-link text-white">
                                <a1>Contact</a1>
                            </a>
                        </li>
                        <!-- <li>
                            <a href="./ICRA2022.html" class="nav-link text-white">
                                <a1>ICRA2022</a1>
                            </a>
                        </li> -->
                        <li>
                            <a href="#organizers" class="nav-link text-white">
                                <a1>Organizers</a1>
                            </a>
                        </li>
                    </ul>
                    <!-- <div class="text-end">
                        <button type="button" class="btn btn-outline-light me-2" id="login_btn" data-bs-toggle="modal" data-bs-target="#login">Login</button>
                        <button type="button" class="btn btn-warning" id="signup_btn" data-bs-toggle="modal" data-bs-target="#signup">Login</button>
                    </div> -->
                </div>
            </div>
        </header>



        <div class="container1">
            <img1><img src="cover.png" class="img-fluid" alt="img-responsive"></img1>
        </div>
        <div class="container p-4 anchor">
            <h1 class="text-white" id="introduction">Introduction</h1>
            <hr>
            <p class="text-white-50">
                In the rapidly evolving domain of autonomous driving, the accuracy and resilience of perception systems are paramount.
                Recent advancements, particularly in bird's eye view (BEV) representations and LiDAR sensing technologies, have significantly improved in-vehicle 3D scene perception.
            </p>

            <p class="text-white-50">
                Yet, the robustness of 3D scene perception methods under varied and challenging conditions — integral to ensuring safe operations — has been insufficiently assessed.
                To fill in the existing gap, we introduce <strong>The RoboDrive Challenge</strong>, seeking to push the frontiers of robust autonomous driving perception.
            </p>

            <p class="text-white-50">
                RoboDrive is one of the first benchmarks that targeted probing the Out-of-Distribution (OoD) robustness of state-of-the-art autonomous driving perception models, centered around two mainstream topics: <strong>common corruptions</strong> and <strong>sensor failures</strong>. 
            </p>


            <img1><img src="teaser.png" class="img-fluid" alt="img-responsive"></img1>


            <p class="text-white"><strong>Topic One: Corruptions</strong></p>

            <p class="text-white-50">
                There are eighteen real-world corruption types in total, ranging from three perspectives: 
            </p>

            <p class="text-white-50">
                &nbsp;&nbsp;&nbsp;&nbsp;
                - Weather and lighting conditions, such as bright, low-light, foggy, and snowy conditions.
                <br>&nbsp;&nbsp;&nbsp;&nbsp;
                - Movement and acquisition failures, such as potential blurs caused by vehicle motions.
                <br>&nbsp;&nbsp;&nbsp;&nbsp;
                - Data processing issues, such as noises and quantizations happen due to hardware malfunctions.
            </p>

            <p class="text-white"><strong>Topic Two: Sensor Failures</strong></p>

            <p class="text-white-50">
                Additionally, we aim to probe the 3D scene perception robustness under camera and LiDAR sensor failures:
            </p>

            <p class="text-white-50">
                &nbsp;&nbsp;&nbsp;&nbsp;
                - Loss of certain camera frames during the driving system sensing process.
                <br>&nbsp;&nbsp;&nbsp;&nbsp;
                - Loss of one or more camera views during the driving system sensing process.
                <br>&nbsp;&nbsp;&nbsp;&nbsp;
                - Loss of the roof-top LiDAR view during the driving system sensing process.
            </p>

            
            <p class="text-white"><strong>Challenge Tracks</strong></p>

            <p class="text-white-50">
                There are <strong>five tracks</strong> in this RoboDrive Challenge, with emphasis on the following 3D scene perception tasks:
            </p>

            <p class="text-white-50">
                &nbsp;&nbsp;&nbsp;&nbsp;
                - Track 1: Robust BEV Detection.
                <br/>&nbsp;&nbsp;&nbsp;&nbsp;
                - Track 2: Robust Map Segmentation.
                <br/>&nbsp;&nbsp;&nbsp;&nbsp;
                - Track 3: Robust Occupancy Prediction.
                <br/>&nbsp;&nbsp;&nbsp;&nbsp;
                - Track 4: Robust Depth Estimation.
                <br/>&nbsp;&nbsp;&nbsp;&nbsp;
                - Track 5: Robust Multi-Modal BEV Detection.
            </p>

            <p class="text-white-50">
                For additional implementation details, kindly refer to our <a href="https://github.com/Daniel-xsy/RoboBEV" target="_blank">RoboBEV</a>, <a href="https://github.com/ldkong1205/RoboDepth" target="_blank">RoboDepth</a>, and <a href="https://github.com/ldkong1205/Robo3D" target="_blank">Robo3D</a> projects.
            </p>


            <p class="text-white-50">
                <strong>E-mail:</strong> <a href="mailto:robodrive.2024@gmail.com" target="_blank">robodrive.2024@gmail.com</a>.
            </p>



            <br/><br/>

            <h1 class="text-white" id="venue">Venue</h1>
            <hr/>

            <!-- <img1>
                <div style="text-align: center;">
                    <img src="icra2024.png" class="img-fluid" alt="img-responsive" width="20%">
                </div>
            </img1> -->

            <p>
                <img src="icra2024.png" align="right" width="24.5%" hspace="22" vspace="5">
            </p>


            <p class="text-white-50">
                The RoboDrive Challenge is affiliated with the 41st IEEE Conference on Robotics and Automation (ICRA 2024).
            </p>

            <p class="text-white-50">
                ICRA is IEEE Robotics and Automation Society's flagship conference. ICRA 2024 will be held from May 13th to 17th, 2024, in Yokohama, Japan.
            </p>

            <p class="text-white-50">
                The ICRA competitions provide a unique venue for state-of-the-art technical demonstrations from research labs throughout academia and industry.
                For additional details, kindly refer to the ICRA 2024 <a href="https://2024.ieee-icra.org/" target="_blank">website</a>.
            </p>



            <br/><br/>

            <h1 class="text-white" id="venue">RoboDrive Workshop</h1>
            <hr/>

            <p>
                <img src="workshop.png" align="right" width="50%" hspace="15" vspace="15">
            </p>


            <p class="text-white-50">
                Our workshop is scheduled to be held on Wednesday, May 15th, 2024, from 1:00 P.M. to 5:00 P.M. JST (UTC+9).
            </p>

            <p class="text-white-50">
                For <strong>on-site</strong> attendance:
                Visit us at the Competition Hall, Pacific Convention Plaza Yokohama (PACIFICO Yokohama) 1-1-1, Minato Mirai, Nishi-ku, Yokohama 220-0012, Japan.
            </p>

            <p class="text-white-50">
                For <strong>online</strong> attendance:
                Join us using <a href="https://cmu.zoom.us/j/96870741709?pwd=UjI1bUhtU1k2MCt5c2Z5VFlaNnc4QT09" target="_blank">this</a> ZOOM link.
            </p>

            <p class="text-white-50">
                The workshop slides can be found from <a href="https://robodrive-24.github.io/workshop.pdf" target="_blank">here</a>.
            </p>



            <br/><br/>

            <h1 class="text-white" id="toolkit">Toolkit</h1>
            <hr/>

            <div class="container text-center p-1 text-white">
                <div class="row">
                    <div class="col"> <img src="static/logo-image/github.png" class="rounded-circle" width="136">
                        <p></p>
                        <h5><a href="https://github.com/robodrive-24/toolkit" target="_blank">GitHub</a></h5>
                        <p></p>
                    </div>

                    <div class="col"> <img src="static/logo-image/arxiv.png" class="rounded-circle" width="136">
                        <p></p>
                        <h5><a href="https://arxiv.org/abs/2405.08816" target="_blank">Tech Report</a></h5>
                    </div>

                    <div class="col"> <img src="static/logo-image/robobev.png" class="rounded-circle" width="136">
                        <p></p>
                        <h5><a href="https://github.com/Daniel-xsy/RoboBEV" target="_blank">RoboBEV</a></h5>
                    </div>

                    <div class="col"> <img src="static/logo-image/openmmlab.png" class="rounded-circle" width="136">
                        <p></p>
                        <h5><a href="https://github.com/open-mmlab/mmdetection3d" target="_blank">MMDetection3D</a></h5>
                    </div>

                </div>
            </div>

            
            
            <br/><br/>

            <h1 class="text-white" id="tracks">Challenge One: Corruptions</h1>
            <hr/>

            <!-- <h2 class="text-white" id="tracks">Topic One: </h2>
            <hr/> -->

            <div class="row row-cols-1 row-cols-md-2 mb-3 text-center align-content-center text-white">
                <div class="col">
                    <div class="card rounded-3 shadow-sm">
                        <div class="card-header py-3 bg-openmmlab">
                            <h4 class="my-0 fw-normal text-black">Track 1</h4>
                        </div>
                        <div class="card-body bg-black">
                            <h3>Robust BEV Detection</h3>

                            <ul class="list-unstyled mt-3 mb-4">
                                <li>Evaluating the resilience of detection algorithms against diverse environmental and sensor-based corruptions</li>
                            </ul>
                            <a href="https://codalab.lisn.upsaclay.fr/competitions/17135" target="_blank"><button type="button" class="w-100 btn btn-lg btn-outline-warning">Evaluation Server 1</button></a>
                        </div>
                    </div>
                </div>
                <div class="col">
                    <div class="card mb-4 rounded-3 shadow-sm">
                        <div class="card-header py-3 bg-openmmlab">
                            <h4 class="my-0 fw-normal text-black">Track 2</h4>
                        </div>
                        <div class="card-body bg-black">
                            <h3>Robust Map Segmentation</h3>
                            <ul class="list-unstyled mt-3 mb-4">
                                <li>Focusing on the segmentation of complex driving scene elements in BEV maps under varied driving conditions</li>
                            </ul>

                            <a href="https://codalab.lisn.upsaclay.fr/competitions/17062" target="_blank"><button type="button" class="w-100 btn btn-lg btn-outline-warning">Evaluation Server 2</button></a>
                        </div>
                    </div>
                </div>
                <div class="col">
                    <div class="card rounded-3 shadow-sm">
                        <div class="card-header py-3 bg-openmmlab">
                            <h4 class="my-0 fw-normal text-black">Track 3</h4>
                        </div>
                        <div class="card-body bg-black">
                            <h3>Robust Occupancy Prediction</h3>

                            <ul class="list-unstyled mt-3 mb-4">
                                <li>Testing the accuracy of occupancy grid predictions in dynamic and unpredictable real-world driving environments</li>
                            </ul>
                            <a href="https://codalab.lisn.upsaclay.fr/competitions/17063" target="_blank"><button type="button" class="w-100 btn btn-lg btn-outline-warning">Evaluation Server 3</button></a>
                        </div>
                    </div>
                </div>
                <div class="col">
                    <div class="card mb-4 rounded-3 shadow-sm">
                        <div class="card-header py-3 bg-openmmlab">
                            <h4 class="my-0 fw-normal text-black">Track 4</h4>
                        </div>
                        <div class="card-body bg-black">
                            <h3>Robust Depth Estimation</h3>
                            <ul class="list-unstyled mt-3 mb-4">
                                <li>Assessing the depth estimation robustness from multiple perspectives for comprehensive 3D scene perception</li>
                            </ul>

                            <a href="https://codalab.lisn.upsaclay.fr/competitions/17226" target="_blank"><button type="button" class="w-100 btn btn-lg btn-outline-warning">Evaluation Server 4</button></a>
                        </div>
                    </div>
                </div>
            </div>



            <br/><br/>


            <h1 class="text-white" id="tracks">Challenge Two: Sensor Failures</h1>
            <hr/>

            <div class="row row-cols-1 row-cols-md-2 mb-3 text-center align-content-center text-white">
                <div class="col">
                    <div class="card mb-4 rounded-3 shadow-sm">
                        <div class="card-header py-3 bg-openmmlab">
                            <h4 class="my-0 fw-normal text-black">Track 5</h4>
                        </div>
                        <div class="card-body bg-black">
                            <h3>Robust Multi-Modal BEV Detection</h3>
                            <ul class="list-unstyled mt-3 mb-4">
                                <li>Tailored for evaluating the reliability of advanced driving perception systems equipped with multiple types of sensors</li>
                            </ul>

                            <a href="https://codalab.lisn.upsaclay.fr/competitions/17137" target="_blank"><button type="button" class="w-100 btn btn-lg btn-outline-warning">Evaluation Server 5</button></a>
                        </div>
                    </div>
                </div>
            </div>



            <br/><br/>


            <h1 class="text-white" id="timeline">Timeline</h1>
            <hr>

            <div id="timeline-content">
                <ul class="timeline">
                    <li class="event" data-date="&nbsp;&nbsp;&nbsp;Registration">
                        <h3>Team Up</h3>
                        <p>Register for your team by filling in <a href="https://forms.gle/hnaezVhEycPAjUD78" target="_blank">this</a> Google Form.&nbsp;</p>
                    </li>
                    <li class="event" data-date="Jan. 05, 2023">
                        <h3>Release of Training and Evaluation Data</h3>
                        <p>Download the data from the competition toolkit.&nbsp;</p>
                    </li>
                    <li class="event" data-date="Jan. 15, 2024">
                        <h3>Competition Servers Online @ CodaLab</h3>
                    </li>
                    <li class="event" id="date" data-date="Mar. 31, 2024">
                        <h3>Phase One Deadline</h3>
                        <p></p>
                        <p>Shortlisted teams are invited to participate in the next phase.&nbsp;</p>
                    </li>
                    <li class="event" id="date" data-date="Apr. 30, 2024">
                        <h3>Phase Two Deadline</h3>
                        <p></p>
                        <p>Don't forget to include the code link in your submissions.&nbsp;</p>
                    </li>
                    <li class="event" data-date="May 17, 2024">

                        <h3>Award Decision Announcement</h3>
                        <p></p>
                        <p>Associated with the ICRA 2024 conference formality.&nbsp;</p>
                    </li>
                </ul>
            </div>


            <h1 class="text-white" id="awards">Awards</h1>
            <hr />
            <div class="row row-cols-1 row-cols-md-2 mb-3 text-center align-content-center text-white">
                <div class="col">
                    <div class="card rounded-3 shadow-sm">
                        <div class="card-header py-3 bg-openmmlab">
                            <h4 class="my-0 fw-normal text-black">1st Place</h4>
                        </div>
                        <div class="card-body bg-black">
                            <h3>Cash $ 5000 + Certificate</h3>
                            <ul class="list-unstyled mt-3 mb-4">
                                <li>This award will be given to five awardees; an amount of $ 1000 will be given to each track..</li>
                            </ul>
                        </div>
                        
                    </div>
                </div>
                <div class="col">
                    <div class="card mb-4 rounded-3 shadow-sm">
                        <div class="card-header py-3 bg-openmmlab">
                            <h4 class="my-0 fw-normal text-black">2nd Place</h4>
                        </div>
                        <div class="card-body bg-black">
                            <h3>Cash $ 3000 + Certificate</h3>
                            <ul class="list-unstyled mt-3 mb-4">
                                <li>This award will be given to five awardees; an amount of $ 600 will be given to each track..</li>
                            </ul>
                        </div>
                    </div>
                </div>
                <div class="col">
                    <div class="card mb-4 rounded-3 shadow-sm">
                        <div class="card-header py-3 bg-openmmlab">
                            <h4 class="my-0 fw-normal text-black">3rd Place</h4>
                        </div>
                        <div class="card-body bg-black">
                            <h3>Cash $ 2000 + Certificate</h3>
                            <ul class="list-unstyled mt-3 mb-4">
                                <li>This award will be given to five awardees; an amount of $ 400 will be given to each track.</li>
                            </ul>
                        </div>
                    </div>
                </div>
                <div class="col">
                    <div class="card mb-4 rounded-3 shadow-sm">
                        <div class="card-header py-3 bg-warning">
                            <h4 class="my-0 fw-normal text-black">Innovative Award</h4>
                        </div>
                        <div class="card-body bg-black">
                            <h3>Certificate</h3>
                            <ul class="list-unstyled mt-3 mb-4">
                                <li>This award will be selected by the program committee and given to ten awardees; two per track.</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>


            <br/><br/>


            <h1 class="text-white" id="evaluation">Submission & Evaluation</h1>
            <hr>

            <p class="text-white-50">
                In this competition, all participants are expected to adopt the official <a href="https://www.nuscenes.org/nuscenes" target="_blank">nuScenes</a> dataset for model training and our robustness probing sets for model evaluation.
                Additional data sources are <strong>NOT</strong> allowed in this competition.
            </p>

            <p class="text-white-50">
                Kindly refer to <a href="https://github.com/robodrive-24/toolkit/blob/main/docs/DATA_PREPARE.md" target="_blank">DATA_PREPARE.md</a> for the details to prepare the training and evaluation data.
            </p>

            <p class="text-white-50">
                For all five tracks in this RoboDrive competition, the participants are expected to submit their predictions to the <strong>EvalAI</strong> servers for model evaluation. 
            </p>

            <p class="text-white-50">
                To facilitate the training and evaluation, we have provided detailed instructions and a baseline model for each track. Kindly refer to <a href="https://github.com/robodrive-24/toolkit/blob/main/docs/GET_STARTED.md" target="_blank">GET_STARTED.md</a> for additional details.
            </p>




            <br/><br/>

            <h1 class="text-white" id="organizers">FAQs</h1>
            <hr>

            <p class="text-white-50">
                Please refer to <a href="https://github.com/robodrive-24/toolkit/blob/main/docs/GET_STARTED.md#frequently-asked-questions" target="_blank">Frequently Asked Questions</a> for more detailed rules and conditions of this competition.
            </p>




            <br/><br/>

            
            <h1 class="text-white" id="contact">Contact</h1>
            <hr>
            
            <div class="container text-center p-1 text-white">
                <div class="row">
                    <div class="col"> <img src="static/logo-image/email.png" class="rounded-circle" width="115">
                        <p></p>
                        <h5><a href="mailto:robodrive.2024@gmail.com" target="_blank">E-mail</a></h5>
                    </div>

                    <div class="col"> <img src="static/logo-image/twitter.png" class="rounded-circle" width="115">
                        <p></p>
                        <h5><a href="https://twitter.com/RoboDrive2024" target="_blank">Twitter</a></h5>
                    </div>

                    <div class="col"> <img src="static/logo-image/wechat.png" class="rounded-circle" width="115">
                        <p></p>
                        <h5><a href="wechat_qr.jpg" target="_blank">WeChat</a></h5>
                    </div>

                    <div class="col"> <img src="static/logo-image/slack.png" class="rounded-circle" width="115">
                        <p></p>
                        <h5><a href="https://join.slack.com/t/robodrive/shared_invite/zt-29fnp2iye-QZtwxSdCchil6noIiTxoXg" target="_blank">Slack</a></h5>
                    </div>

                    <div class="col"> <img src="static/logo-image/zhihu.png" class="rounded-circle" width="115">
                        <p></p>
                        <h5><a href="https://zhuanlan.zhihu.com/p/672925784" target="_blank">Zhihu</a></h5>
                    </div>

                    <div class="col"> <img src="static/logo-image/openmmlab.png" class="rounded-circle" width="115">
                        <p></p>
                        <h5><a href="https://openmmlab.com/" target="_blank">OpenMMLab</a></h5>
                    </div>

                </div>
            </div>



            
            <br/><br/>



            <h1 class="text-white" id="organizers">Organizers</h1>
            <hr>
            <div class="container text-center p-1 text-white">
                <div class="row">
                    <div class="col">
                        <a href="https://ldkong.com/" target="_blank">
                            <img src="static/people-image/lingdong.jpg" class="rounded-circle" width="139">
                        </a>
                        <h4>Lingdong Kong</h4> <p><small>NUS Computing</small></p>
                    </div>
                    <div class="col">
                        <a href="https://daniel-xsy.github.io/" target="_blank">
                            <img src="static/people-image/shaoyuan.jpeg" class="rounded-circle" width="139">
                        </a>
                        <h4>Shaoyuan Xie</h4> <p><small>UC, Irvine</small></p>
                    </div>
                    <div class="col">
                        <a href="https://hanjianghu.net/" target="_blank">
                            <img src="static/people-image/hanjiang.png" class="rounded-circle" width="139">
                        </a>
                        <h4>Hanjiang Hu</h4> <p><small>Carnegie Mellon</small></p>
                    </div>
                    <div class="col">
                        <a href="https://yaruniu.com/" target="_blank">
                            <img src="static/people-image/yaru.jpeg" class="rounded-circle" width="139">
                        </a>
                        <h4>Yaru Niu</a></h4> <p><small>Carnegie Mellon</small></p>
                    </div>
                </div>
            </div>

            <br/>

            <div class="container text-center p-1 text-white">
                <div class="row">
                    <div class="col">
                        <a href="https://www.comp.nus.edu.sg/cs/people/ooiwt/" target="_blank">
                            <img src="static/people-image/weitsang.jpeg" class="rounded-circle" width="139">
                        </a>
                        <h4>Wei Tsang Ooi</h4> <p><small>NUS Computing</small></p>
                    </div>
                    <div class="col">
                        <a href="https://ipal.cnrs.fr/benoit-cottereau-personal-page/" target="_blank">
                            <img src="static/people-image/benoit.jpg" class="rounded-circle" width="139">
                        </a>
                        <h4>Benoit R. Cottereau</h4> <p><small>CNRS & IPAL</small></p>
                    </div>
                    <div class="col">
                        <a href="https://ipal.cnrs.fr/lai-xing-ng/" target="_blank">
                            <img src="static/people-image/laixing.jpeg" class="rounded-circle" width="139">
                        </a>
                        <h4>Lai Xing Ng</h4> <p><small>A*STAR, I2R</small></p>
                    </div>
                    <div class="col">
                        <a href="https://yuexinma.me/aboutme.html" target="_blank">
                            <img src="static/people-image/yuexin.jpeg" class="rounded-circle" width="139">
                        </a>
                        <h4>Yuexin Ma</h4> <p><small>Shanghai Tech</small></p>
                    </div>
                </div>
            </div>

            <br/>

            <div class="container text-center p-1 text-white">
                <div class="row">
                    <div class="col">
                        <a href="https://zhangwenwei.cn/" target="_blank">
                            <img src="static/people-image/wenwei.png" class="rounded-circle" width="139">
                        </a>
                        <h4>Wenwei Zhang</h4> <p><small>Shanghai AI Lab</small></p>
                    </div>
                    <div class="col">
                        <a href="https://github.com/paul007pl" target="_blank">
                            <img src="static/people-image/liang_pan.jpeg" class="rounded-circle" width="139">
                        </a>
                        <h4>Liang Pan</h4> <p><small>Shanghai AI Lab</small></p>
                    </div>
                    <div class="col">
                        <a href="https://chenkai.site/" target="_blank">
                            <img src="static/people-image/kai_chen.jpeg" class="rounded-circle" width="139">
                        </a>
                        <h4>Kai Chen</h4> <p><small>Shanghai AI Lab</small></p>
                    </div>
                    <div class="col">
                        <a href="https://liuziwei7.github.io/" target="_blank">
                            <img src="static/people-image/ziwei.png" class="rounded-circle" width="139">
                        </a>
                        <h4>Ziwei Liu</a></h4> <p><small>NTU, S-Lab</p>
                    </div>
                </div>
            </div>
            
            

            <br/><br/>

            <h1 class="text-white" id="organizers">Sponsors</h1>
            <hr>

            <p class="text-white-50">
                This competition is generously supported by <a href="https://www.noahlab.com.hk/#/home" target="_blank">HUAWEI Noah's Ark Lab</a>.
            </p>
            
            <img1><img src="logo_sponsor.png" class="img-fluid" alt="img-responsive"></img1>


            <br/><br/>


            <h1 class="text-white" id="organizers">Program Committee</h1>
            <hr>
            <div class="container text-center p-1 text-white">
                <div class="row">
                    <div class="col">
                        <a href="https://www.linkedin.com/in/wei-zhang-428b4298/?originalSubdomain=uk" target="_blank">
                            <img src="static/people-image/wei_zhang.jpg" class="rounded-circle" width="139">
                        </a>
                        <h4>Wei Zhang</h4> <p><small>HUAWEI Noah's Ark Lab</small></p>
                    </div>
                    <div class="col">
                        <a href="https://scholar.google.com.hk/citations?user=9_AUwFUAAAAJ" target="_blank">
                            <img src="static/people-image/weichao.jpeg" class="rounded-circle" width="139">
                        </a>
                        <h4>Weichao Qiu</a></h4> <p><small>HUAWEI Noah's Ark Lab</small></p>
                    </div>
                    <div class="col">
                    </div>
                    <div class="col">
                    </div>
                </div>
            </div>
            

            

            <br/><br/>

            <h1 class="text-white" id="organizers">References</h1>
            <hr>

            <p class="text-white-50">
                [1] S. Xie, L. Kong, W. Zhang, J. Ren, L. Pan, K. Chen, and Z. Liu. "<strong>Benchmarking and Analyzing Bird's Eye View Perception Robustness to Corruptions</strong>," Preprint, 2023.
                <a href="https://daniel-xsy.github.io/robobev/static/pdf/RoboBEV.pdf" target="_blank">[Link]</a> <a href="https://github.com/Daniel-xsy/RoboBEV" target="_blank">[Code]</a>
            </p>

            <p class="text-white-50">
                [2] L. Kong, S. Xie, H. Hu, L. X. Ng, B. R. Cottereau, and W. T. Ooi. "<strong>RoboDepth: Robust Out-of-Distribution Depth Estimation under Corruptions</strong>," NeurIPS, 2023.
                <a href="https://arxiv.org/abs/2310.15171" target="_blank">[Link]</a> <a href="https://github.com/ldkong1205/RoboDepth" target="_blank">[Code]</a>
            </p>
            
            <p class="text-white-50">
                [3] L. Kong, Y. Liu, X. Li, R. Chen, W. Zhang, J. Ren, L. Pan, K. Chen, and Z. Liu. "<strong>Robo3D: Towards Robust and Reliable 3D Perception against Corruptions</strong>," ICCV, 2023.
                <a href="https://arxiv.org/abs/2303.17597" target="_blank">[Link]</a> <a href="https://github.com/ldkong1205/Robo3D" target="_blank">[Code]</a>
            </p>


            
            <br/><br/>

            <h1 class="text-white" id="organizers">Affiliations</h1>
            <hr>
            
            
            <p class="text-white-50">
                This competition is hosted by <a href="https://shlab.org.cn/" target="_blank">Shanghai AI Laboratory</a>.
            </p>
            
            <img1><img src="logos.png" class="img-fluid" alt="img-responsive"></img1>


            <br/><br/>


            <h1 class="text-white" id="organizers">Acknowledgements</h1>
            <hr>

            <p class="text-white-50">
                This competition is developed based on the <a href="https://github.com/Daniel-xsy/RoboBEV" target="_blank">RoboBEV</a>, <a href="https://github.com/ldkong1205/RoboDepth" target="_blank">RoboDepth</a>, and <a href="https://github.com/ldkong1205/Robo3D" target="_blank">Robo3D</a> projects.
            </p>

            <p class="text-white-50">
                The evaluation sets of this competition are constructed based on the <a href="https://www.nuscenes.org/nuscenes" target="_blank">nuScenes</a> dataset from <a href="https://motional.com/" target="_blank">Motional AD LLC</a>.
            </p>

            <p class="text-white-50">
                Part of the content of this website is adopted from <a href="https://robodepth.github.io/" target="_blank">The RoboDepth Challenge @ ICRA 2023</a>.
                We would like to thank Jiarun Wei and Shuai Wang for building up the template from the <a href="http://seasondepth-challenge.org/" target="_blank">SeasonDepth</a> website.
            </p>


            <br/><br/>


            <h1 class="text-white" id="organizers">Affiliated Project</h1>
            <hr>

            <p class="text-white-50">
                This project is affiliated with <a href="https://descartes.cnrsatcreate.cnrs.fr/" target="_blank">DesCartes</a>, a <a href="https://www.cnrsatcreate.cnrs.fr/" target="_blank">CNRS@CREATE</a> program on Intelligent Modeling for Decision-Making in Critical Urban Systems.
            </p>

            <img1><img src="logo_descartes.png" class="img-fluid" alt="img-responsive"></img1>





            <br/><br/>

            <h1 class="text-white" id="venue">Winning Team</h1>
            <hr/>

            <p class="text-white-50">
            We are glad to announce the winning teams of the 2024 RoboDrive Challenge!
            </p>


            <h4 class="text-white" id="venue">Track 1: Robust BEV Detection</h4>

            <h5 class="text-white" id="venue">1st: DeepVision</h5>
            <p class="text-white-50">
                - <strong>Team:</strong> Xu Cao, Hao Lu, Ying-Cong Chen
                <br/>
                - <strong>Affiliation:</strong> HKUST (Guangzhou), HKUST          
            </p>

            <h5 class="text-white" id="venue">2nd: Ponyville Autonauts Ltd</h5>
            <p class="text-white-50">
                - <strong>Team:</strong> Caixin Kang, Xinning Zhou, Chengyang Ying, Wentao Shang, Xingxing Wei, Yinpeng Dong
                <br/>
                - <strong>Affiliation:</strong> Beihang U., Tsinghua U., Hefei U. of Technology
            </p>

            <h5 class="text-white" id="venue">3rd: CyberBEV</h5>
            <p class="text-white-50">
                - <strong>Team:</strong> Bo Yang, Shengyin Jiang, Zeliang Ma, Dengyi Ji, Haiwen Li
                <br/>
                - <strong>Affiliation:</strong> Beijing U. of Posts and Telecommunications, Beijing U. of Technology                 
            </p>

            <hr/>

            <h4 class="text-white" id="venue">Track 2: Robust Map Segmentation</h4>
    
            <h5 class="text-white" id="venue">1st: SafeDrive-SSR</h5>
            <p class="text-white-50">
                - <strong>Team:</strong> Xingliang Huang, Yu Tian
                <br/>
                - <strong>Affiliation:</strong> U. of Chinese Academy of Sciences, Tsinghua U.
            </p>

            <h5 class="text-white" id="venue">2nd: CrazyFriday</h5>
            <p class="text-white-50">
                - <strong>Team:</strong> Genghua Kou, Fan Jia, Yingfei Liu, Tiancai Wang, Ying Li
                <br/>
                - <strong>Affiliation:</strong> Beijing Institute of Technology, Megvii Technology                
            </p>

            <h5 class="text-white" id="venue">3rd: Samsung Research</h5>
            <p class="text-white-50">
                - <strong>Team:</strong> Xiaoshuai Hao, Yifan Yang, Hui Zhang, Mengchuan Wei, Yi Zhou, Haimei Zhao, Jing Zhang
                <br/>
                - <strong>Affiliation:</strong> Samsung R&D Institute China Beijing, The U. of Sydney
            </p>

            <hr/>

            <h4 class="text-white" id="venue">Track 3: Robust Occupancy Prediction</h4>
    
            <h5 class="text-white" id="venue">1st: ViewFormer</h5>
            <p class="text-white-50">
                - <strong>Team:</strong> Jinke Li, Xiao He, Xiaoqiang Cheng
                <br/>
                - <strong>Affiliation:</strong> UISEE
            </p>

            <h5 class="text-white" id="venue">2nd: APEC Blue</h5>
            <p class="text-white-50">
                - <strong>Team:</strong> Bingyang Zhang, Lirong Zhao, Dianlei Ding, Fangsheng Liu, Yixiang Yan, Hongming Wang
                <br/>
                - <strong>Affiliation:</strong> SongGuo7, Beijing APEC Blue Technology Co., Ltd, Beihang U.             
            </p>

            <h5 class="text-white" id="venue">3rd: hm.unilab</h5>
            <p class="text-white-50">
                - <strong>Team:</strong> Nanfei Ye, Lun Luo, Yubo Tian, Yiwei Zuo, Zhe Cao, Yi Ren, Yunfan Li, Wenjie Liu, Xun Wu
                <br/>
                - <strong>Affiliation:</strong> Haomo.ai
            </p>

            <hr/>

            <h4 class="text-white" id="venue">Track 4: Robust Depth Estimation</h4>

            <h5 class="text-white" id="venue">1st: HIT-AIIA</h5>
            <p class="text-white-50">
                - <strong>Team:</strong> Yifan Mao, Ming Li, Jian Liu, Jiayang Liu, Zihan Qin, Cunxi Chu, Jialei Xu, Wenbo Zhao, Junjun Jiang, Xianming Liu
                <br/>
                - <strong>Affiliation:</strong> Harbin Institute of Technology
            </p>

            <h5 class="text-white" id="venue">2nd: BUAA-Trans</h5>
            <p class="text-white-50">
                - <strong>Team:</strong> Ziyan Wang, Chiwei Li, Shilong Li, Chendong Yuan, Songyue Yang, Wentao Liu, Peng Chen, and Bin Zhou
                <br/>
                - <strong>Affiliation:</strong> Beihang U.
            </p>

            <h5 class="text-white" id="venue">3rd: CUSTZS</h5>
            <p class="text-white-50">
                - <strong>Team:</strong> Yubo Wang, Chi Zhang, Jianhang Sun
                <br/>
                - <strong>Affiliation:</strong> Zhongshan Institute, Changchun U. of Science and Technology
            </p>

            <hr/>

            <h4 class="text-white" id="venue">Track 5: Robust Multi-Modal BEV Detection</h4>

            <h5 class="text-white" id="venue">1st: safedrive-promax</h5>
            <p class="text-white-50">
                - <strong>Team:</strong> Xiao Yang, Hai Chen, Lizhong Wang
                <br/>
                - <strong>Affiliation:</strong> Tsinghua U.
            </p>

            <h5 class="text-white" id="venue">2nd: Ponyville Autonauts Ltd</h5>
            <p class="text-white-50">
                - <strong>Team:</strong> Caixin Kang, Xinning Zhou, Chengyang Ying, Wentao Shang, Xingxing Wei, Yinpeng Dong
                <br/>
                - <strong>Affiliation:</strong> Beihang U., Tsinghua U., Hefei U. of Technology                
            </p>

            <h5 class="text-white" id="venue">3rd: HITSZrobodrive</h5>
            <p class="text-white-50">
                - <strong>Team:</strong> Dongyi Fu, Yongchun Lin, Huitong Yang, Haoang Li, Yadan Luo, Xianjing Cheng, Yong Xu 
                <br/>
                - <strong>Affiliation:</strong> Harbin Institute of Technology (Shenzhen), Guangdong U. of Technology, HKUST (Guangzhou), The U. of Queensland                
            </p>





            <br/><br/>

            <h1 class="text-white" id="venue">Technical Report</h1>
            <hr/>

            <p class="text-white-50">
                - Xu Cao, Hao Lu, and Ying-Cong Chen.
                “<a href="https://robodrive-24.github.io/track1_deep_vision.pdf" target="_blank">
                    Towards Robust Multi-Camera 3D Object Detection through Temporal Sequence Mix Augmentation
                </a>”, Technical Report, 2024.
            </p>

            <p class="text-white-50">
                - Caixin Kang, Xinning Zhou, Chengyang Ying, Wentao Shang, Xingxing Wei, and Yinpeng Dong.
                “<a href="https://robodrive-24.github.io/track1_ponyville.pdf" target="_blank">
                    MVE: Multi-View Enhancer for Robust Bird's Eye View Object Detection
                </a>”, Technical Report, 2024.
            </p>

            <p class="text-white-50">
                - Bo Yang, Shengyin Jiang, Zeliang Ma, Dengyi Ji, and Haiwen Li.
                “<a href="https://robodrive-24.github.io/track1_cyber_bev.pdf" target="_blank">
                    FocalAngle3D: An Angle-Enhanced Two-Stage Model for 3D Detection
                </a>”, Technical Report, 2024.
            </p>

            <p class="text-white-50">
                - Xingliang Huang and Yu Tian.
                “<a href="https://robodrive-24.github.io/track2_safe_drive_ssr.pdf" target="_blank">
                    Models and Data Enhancements for Robust Map Segmentation in Autonomous Driving
                </a>”, Technical Report, 2024.
            </p>

            <p class="text-white-50">
                - Xiaoshuai Hao, Yifan Yang, Hui Zhang, Mengchuan Wei, Yi Zhou, Haimei Zhao, and Jing Zhang.
                “<a href="https://robodrive-24.github.io/track2_crazy_friday.pdf" target="_blank">
                    Using Temporal Information and Mixing-Based Data Augmentations for Robust HD Map Construction
                </a>”, Technical Report, 2024.
            </p>

            <p class="text-white-50">
                - Genghua Kou, Fan Jia, Yingfei Liu, Tiancai Wang, and Ying Li.
                “<a href="https://robodrive-24.github.io/track2_samsung.pdf" target="_blank">
                    MultiViewRobust: Scaling Up Pretrained Models for Robust Map Segmentation
                </a>”, Technical Report, 2024.
            </p>

            <p class="text-white-50">
                Jinke Li, Xiao He, and Xiaoqiang Cheng.
                “<a href="https://robodrive-24.github.io/track3_view_former.pdf" target="_blank">
                    ViewFormer: Spatiotemporal Modeling for Robust Occupancy Prediction
                </a>”, Technical Report, 2024.
            </p>

            <p class="text-white-50">
                - Bingyang Zhang, Lirong Zhao, Dianlei Ding, Fangsheng Liu, Yixiang Yan, and Hongming Wang.
                “<a href="https://robodrive-24.github.io/track3_apec_blue.pdf" target="_blank">
                    Robust Occupancy Prediction based on Enhanced SurroundOcc
                </a>”, Technical Report, 2024.
            </p>

            <p class="text-white-50">
                - Nanfei Ye, Lun Luo, Xun Wu,  Yubo Tian, Zhe Cao, Yunfan Li, Yiwei Zuo, Wenjie Liu, and Yi Ren.
                “<a href="https://robodrive-24.github.io/track3_hm_unilab.pdf" target="_blank">
                    Improving Out-of-Distribution Robustness of Occupancy Prediction Networks with Advanced Loss Functions
                </a>”, Technical Report, 2024.
            </p>

            <p class="text-white-50">
                - Yifan Mao, Ming Li, Jian Liu, Jiayang Liu, Zihan Qin, Chunxi Chu, Jialei Xu, Wenbo Zhao, Junjun Jiang, and Xianming Liu.
                “<a href="https://robodrive-24.github.io/track4_hit_aiia.pdf" target="_blank">
                    DINO-SD for Robust Multi-View Supervised Depth Estimation
                </a>”, Technical Report, 2024.
            </p>

            <p class="text-white-50">
                - Ziyan Wang, Chiwei Li, Shilong Li, Chendong Yuan,  Songyue Yang, Wentao Liu, Peng Chen, and Bin Zhou.
                “<a href="https://robodrive-24.github.io/track4_buaa_trans.pdf" target="_blank">
                    Fusing Features Across Scales: A Semi-Supervised Attention-Based Approach for Robust Depth Estimation
                </a>”, Technical Report, 2024.
            </p>

            <p class="text-white-50">
                - Yubo Wang, Chi Zhang, and Jianhang Sun.
                “<a href="https://robodrive-24.github.io/track4_custzs.pdf" target="_blank">
                    SD-ViT: Performance and Robustness Enhancements of MonoViT for Multi-View Depth Estimation
                </a>”, Technical Report, 2024.
            </p>

            <p class="text-white-50">
                - Hai Chen, Xiao Yang, and Lizhong Wang.
                “<a href="https://robodrive-24.github.io/track5_safedrive_promax.pdf" target="_blank">
                    ASF: Robust 3D Object Detection by Solving Sensor Failures
                </a>”, Technical Report, 2024.
            </p>

            <p class="text-white-50">
                - Caixin Kang, Xinning Zhou, Chengyang Ying, Wentao Shang, Xingxing Wei, and Yinpeng Dong.
                “<a href="https://robodrive-24.github.io/track5_ponyville.pdf" target="_blank">
                    Cross-Modal Transformers for Robust Multi-Modal BEV Detection
                </a>”, Technical Report, 2024.
            </p>

            <p class="text-white-50">
                - Dongyi Fu, Yongchun Lin, Huitong Yang, Haoang Li, Yadan Luo, Xianjing Cheng, and Yong Xu.
                “<a href="https://robodrive-24.github.io/track5_hitsz_robodrive.pdf" target="_blank">
                    RobuAlign: Robust Alignment in Multi-Modal 3D Object Detection
                </a>”, Technical Report, 2024.
            </p>





            <br/><br/>

            <h1 class="text-white" id="organizers">Terms & Conditions</h1>
            <hr>

            <p class="text-white-50">
            This competition is made freely available to academic and non-academic entities for non-commercial purposes such as academic research, teaching, scientific publications, or personal experimentation.
            Permission is granted to use the data given that you agree:
            </p>
            <p class="text-white-50">
            1. That the data in this competition comes “AS IS”, without express or implied warranty. Although every effort has been made to ensure accuracy, we do not accept any responsibility for errors or omissions.<br/>
            2. That you may not use the data in this competition or any derivative work for commercial purposes as, for example, licensing or selling the data, or using the data with a purpose to procure a commercial gain.<br/>
            3. That you include a reference to RoboDrive (including the benchmark data and the specially generated data for academic challenges) in any work that makes use of the benchmark. For research papers, please cite our preferred publications as listed on our webpage.
            </p>

            <p class="text-white-50">
            To ensure a fair comparison among all participants, we require:
            </p>

            <p class="text-white-50">
            1. All participants must follow the exact same data configuration when training and evaluating their algorithms. Please do not use any public or private datasets other than those specified for model training.<br/>
            2. The theme of this competition is to probe the out-of-distribution robustness of autonomous driving perception models. Theorefore, any use of the corruption and sensor failure types designed in this benchmark is strictly prohibited, including any atomic operation that is comprising any one of the mentioned corruptions.<br/>
            3. To ensure the above two rules are followed, each participant is requested to submit the code with reproducible results before the final result is announced; the code is for examination purposes only and we will manually verify the training and evaluation of each participant's model.
            </p>
            


            <footer class="container p-5">
                <p class="float-lg-end"><a href="#">Back to Top</a></p>
                <p class="text-white">&copy; The RoboDrive Organizing Team. All Rights Researved.</p>
            </footer>
        </div>
    </div>









</body>

</html>