<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="">
  <meta name="keywords" content="3D Scene Understanding, 3D Visual Grounding">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>RoboSense: Track 1</title>

  <link href="https://fonts.googleapis.com/css?family=Nunito" rel="stylesheet">

  <link rel="stylesheet" href="./static2/css/bulma.min.css">
  <link rel="stylesheet" href="./static2/css/index.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  
  <script defer src="./static2/js/fontawesome.all.min.js"></script>
  <link rel="icon" href="../logo.png" type="image/x-icon">

  <style>
    .a {
      color: #ffc000;
    }
    .columns {
      display: flex; justify-content: flex-start; padding: 5px; text-align: left;
    }
    .tag {
      background-color: #f5f5f5; border-radius: 3px; padding: 5px; margin-right: 5px; font-size: 14px; color: #333;
    }
  </style>

<style>
  a.external-link:hover {
    background-color: rgb(109,109,109) !important;
    border-color: rgb(109,109,109) !important;
  }
  </style>

  <style>
    #backToTopBtn {
      position: fixed; bottom: 20px; right: 50px; z-index: 999;
      background-color: #ffc000; color: white; border: none;
      border-radius: 50%; padding: 12px 16px; font-size: 20px; cursor: pointer;
      box-shadow: 0px 4px 8px rgba(0,0,0,0.2); transition: opacity 0.3s; display: none;
    }
    
    #backToTopBtn:hover {
      background-color: #76b900;
    }
    
    @media (max-width: 768px) {
      #backToTopBtn {
        font-size: 18px; padding: 10px 14px;
      }
    }

    .img-hover-effect {
      transition: transform 0.3s ease-in-out;
    }

    .img-hover-effect:hover {
      transform: scale(1.05); /* Zoom to 105% */
    }
    </style>

</head>




<body>


  <button onclick="scrollToTop()" id="backToTopBtn" title="Go to top">‚Üë</button>
  <script>
    window.onscroll = function() {
      scrollFunction();
    };
    function scrollFunction() {
      const button = document.getElementById("backToTopBtn");
      if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
        button.style.display = "block";
      } else {
        button.style.display = "none";
      }
    }
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'smooth' });
    }
  </script>
  
  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>

    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item">
          <span class="icon"><i class="fas fa-home"></i></span>
        </a>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">RoboSense 2025</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://robosense2025.github.io/" target="_blank">Main Page</a>
            <a class="navbar-item" href="https://robosense2025.github.io/track1" target="_blank">Track 1: Driving with Language</a>
            <a class="navbar-item" href="https://robosense2025.github.io/track2" target="_blank">Track 2: Social Navigation</a>
            <a class="navbar-item" href="https://robosense2025.github.io/track3" target="_blank">Track 3: Sensor Placement</a>
            <a class="navbar-item" href="https://robosense2025.github.io/track4" target="_blank">Track 4: Cross-Modal Drone Navigation</a>
            <a class="navbar-item" href="https://robosense2025.github.io/track5" target="_blank">Track 5: Cross-Platform 3D Object Detection</a>
          </div>
        </div>
      </div>
    </div>
  </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <i class="fas fa-car fa-2x" style="color: #76b900; margin-bottom: 12px;"></i>
              <br>
              The <a style="color: #ffc000;">Robo</a><a style="color: #76b900;">Sense</a> Challenge 2025
            </h1>
            <h2 class="title is-2 publication-title">
              Track <a style="color: #76b900;">#1</a>: Driving with Language
            </h2>
          </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section" style="margin-top: 0px;">
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width left">
          <div class="content has-text-justified" style="padding-top: 0px">
            <p>
              <img src="./images/track1/teaser.png" alt="Track 1 Image" class="img-hover-effect" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
            </p>
            <p>
              üëã Welcome to <strong>Track <a style="color: #76b900;">#1</a>: Driving with Language</strong> of the <a href="https://robosense2025.github.io/" target="_blank"><strong>2025 RoboSense Challenge</strong></a>!
            </p>
            <p>
              In the era of autonomous driving, it is increasingly critical for intelligent agents to understand and act upon language-based instructions. 
              Human drivers naturally interpret complex commands involving spatial, semantic, and temporal cues (e.g., "turn left after the red truck" or "stop at the next gas station on your right"). 
              To enable such capabilities in autonomous systems, vision-language models (VLMs) must be able to perceive dynamic driving scenes, understand natural language commands, and make informed driving decisions accordingly.
            </p>
            <p>
              üèÜ Prize Pool: $2,000 USD (1st: $1,000, 2nd: $600, 3rd: $400) + Innovation Awards
            </p>
          </div>

          <hr>

          <h2 class="title is-3">üéØ Objective</h2>
          <div class="content has-text-justified" style="padding-top: 0px">
            <p style="font-size: 1rem; line-height: 1.6; color: #34495e;">
              This track evaluates the capability of VLMs to answer high-level driving questions in complex urban environments. Given question including perception, prediction, and planning, and a multi-view camera input, participants are expected to answer the question given the visual corrupted images.
            </p>
          </div>

          <hr>

          <h2 class="title is-3">üóÇÔ∏è Phases & Requirements</h2>
          <div class="content has-text-justified" style="padding-top: 0px">
          
            <h4 class="title is-4">Phase 1: Clean Image Evaluation</h4>
            <p>
              <strong>Duration:</strong> 15 June 2025 ‚Äì 15 August 2025
            </p>
            <p>
              In this phase, participants are expected to answer the high-level driving questions given the clean images. Participants can:
              - Fine-tune the VLM on custom datasets (including nuScenes, DriveBench, etc.)
              - Develop and test their approaches 
              - Submit results as a json file
              - Iterate and improve their models based on public leaderboard feedback
            <p>
              <strong>Ranking Metric:</strong> Weighted score combining:
            </p>
            <ul>
              <li>Accuracy</li>
              <li>Language-based score</li>
              <li>LLM-based score</li>
            </ul>
            </p>
          
            <hr>
          
            <h4 class="title is-4">Phase 2: Corruption Image Evaluation</h4>
            <p>
              <strong>Duration:</strong> 15 August 2025 ‚Äì 15 October 2025
            </p>
            <p>
              In this phase, participants are expected to answer the high-level driving questions given the corrupted images. Participants can:
              - Fine-tune the VLM on custom datasets (including nuScenes, DriveBench, etc.)
              - Develop and test their approaches 
              - Submit results as a json file
              - Iterate and improve their models based on public leaderboard feedback
            </ul>
            <p>
              <strong>Ranking Metric:</strong> Weighted score combining:
            </p>
            <ul>
              <li>Accuracy</li>
              <li>Language-based score</li>
              <li>LLM-based score</li>
            </ul>
          </div>

          <hr>

          <h2 class="title is-3">üöó Dataset Examples</h2>
          <div class="content has-text-justified" style="padding-top: 0px">
            <p>
              <img src="./images/track1/data_example1.png" alt="Track 1 Image" class="img-hover-effect" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
            </p>
            <p>
              <img src="./images/track1/data_example2.png" alt="Track 1 Image" class="img-hover-effect" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
            </p>
            <p>
              <img src="./images/track1/data_example3.png" alt="Track 1 Image" class="img-hover-effect" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
            </p>
            <p>
              <img src="./images/track1/data_example4.png" alt="Track 1 Image" class="img-hover-effect" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
            </p>
          </div>

          <hr>

          <h2 class="title is-3">üõ†Ô∏è Baseline Model</h2>
          <div class="content has-text-justified" style="padding-top: 0px">
            <p>
              In this track, we adopt Qwen2.5-VL<sub>7B</sub> as our baseline model. Beyond the provided baseline, participants are encouraged to explore alternative strategies to further boost performance:
            </p>
            <ul>
              <li>Retrieval-augmented reasoning</li>
              <li>Multi-frame visual reasoning</li>
              <li>Chain-of-thought reasoning</li>
              <li>Graph-based reasoning</li>
              <li>Vision-based object reference prompting</li>
            </ul>
          </div>

          <hr>

          <h2 class="title is-3">üìä Baseline Results</h2>
          <div class="content has-text-justified" style="padding-top: 0px">
            <p>
              In this track, we use ...
            </p>
            <div class="table-container">
              <table class="table is-bordered is-striped is-hoverable is-fullwidth">
                <thead>
                  <tr>
                    <th>Metric</th>
                    <th>Metric 1</th>
                    <th>Metric 2</th>
                    <th>Metric 3</th>
                    <th>Metric 4</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Baseline Model</td>
                    <td>x.xx</td>
                    <td>x.xx</td>
                    <td>x.xx</td>
                    <td>x.xx</td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>

          <hr>

          <h2 class="title is-3">üîó Resources</h2>
          <div class="content has-text-justified" style="padding-top: 0px">
            <p>
              We provide the following resources to support the development of models in this track:
            </p>
            <div class="table-container">
              <table class="table is-bordered is-striped is-hoverable is-fullwidth">
                <thead>
                  <tr>
                    <th>Resource</th>
                    <th>Link</th>
                    <th></th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td><strong>GitHub</strong></td>
                    <td><a href="https://github.com/robosense2025/track1" target="_blank">https://github.com/robosense2025/track1</a><td>
                  </tr>
                  <tr>
                    <td><strong>Dataset</strong></td>
                    <td>TBD</td>
                  </tr>
                  <tr>
                    <td><strong>Registration</strong></td>
                    <td><a href="https://docs.google.com/forms/d/e/1FAIpQLSdwfvk-NHdQh9-REiBLCjHMcyLT-sPCOCzJU-ux5jbcZLTkBg/viewform?usp=sharing&ouid=111184461807593368933" target="_blank">Google Form</a></td>
                  </tr>
                  <tr>
                    <td><strong>Evaluation Server</strong></td>
                    <td>TBD</td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>

          <hr>





<!-- <h2 class="title is-3">üìñ References</h2>
<div class="content has-text-justified" style="padding-top: 0px;">
  <div style="
    max-width: 100%;
    overflow-x: auto;
    background-color: #f9f9f9;
    border-radius: 5px;
    padding: 1em;
    font-size: 0.9em;
    box-sizing: border-box;
  ">
    <pre style="
      margin: 0;
      font-family: monospace;
      white-space: pre;
      overflow-x: auto;
    ">
@article{xie2025drivebench,
  title     = {},
  author    = {},
  booktitle = {},
  year      = {2025},
  url       = {https://robosense2025.github.io}
}
    </pre>
  </div>
</div> -->




        </div>
      </div>
    </div>
  </section>



  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International</a> license.
            </p>
            <p>
              Copyright ¬© <a style="color: #ffc000;">Robo</a><a style="color: #76b900;">Sense</a> 2025 All Rights Reserved.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>


</body>

</html>