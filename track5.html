<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="">
  <meta name="keywords" content="3D Scene Understanding, 3D Visual Grounding">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>RoboSense: Track 5</title>

  <link href="https://fonts.googleapis.com/css?family=Nunito" rel="stylesheet">

  <link rel="stylesheet" href="./static2/css/bulma.min.css">
  <link rel="stylesheet" href="./static2/css/index.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  
  <script defer src="./static2/js/fontawesome.all.min.js"></script>
  <link rel="icon" href="../logo.png" type="image/x-icon">

  <style>
    .a {
      color: #ffc000;
    }
    .columns {
      display: flex; justify-content: flex-start; padding: 5px; text-align: left;
    }
    .tag {
      background-color: #f5f5f5; border-radius: 3px; padding: 5px; margin-right: 5px; font-size: 14px; color: #333;
    }
  </style>

<style>
  a.external-link:hover {
    background-color: rgb(109,109,109) !important;
    border-color: rgb(109,109,109) !important;
  }
  </style>

  <style>
    #backToTopBtn {
      position: fixed; bottom: 20px; right: 50px; z-index: 999;
      background-color: #ffc000; color: white; border: none;
      border-radius: 50%; padding: 12px 16px; font-size: 20px; cursor: pointer;
      box-shadow: 0px 4px 8px rgba(0,0,0,0.2); transition: opacity 0.3s; display: none;
    }
    
    #backToTopBtn:hover {
      background-color: #76b900;
    }
    
    @media (max-width: 768px) {
      #backToTopBtn {
        font-size: 18px; padding: 10px 14px;
      }
    }

    .img-hover-effect {
      transition: transform 0.3s ease-in-out;
    }

    .img-hover-effect:hover {
      transform: scale(1.05); /* Zoom to 105% */
    }
    </style>

</head>




<body>


  <button onclick="scrollToTop()" id="backToTopBtn" title="Go to top">‚Üë</button>
  <script>
    window.onscroll = function() {
      scrollFunction();
    };
    function scrollFunction() {
      const button = document.getElementById("backToTopBtn");
      if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
        button.style.display = "block";
      } else {
        button.style.display = "none";
      }
    }
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'smooth' });
    }
  </script>
  
  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>

    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item">
          <span class="icon"><i class="fas fa-home"></i></span>
        </a>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">RoboSense 2025</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://robosense2025.github.io/" target="_blank">Main Page</a>
            <a class="navbar-item" href="https://robosense2025.github.io/track1" target="_blank">Track 1: Driving with Language</a>
            <a class="navbar-item" href="https://robosense2025.github.io/track2" target="_blank">Track 2: Social Navigation</a>
            <a class="navbar-item" href="https://robosense2025.github.io/track3" target="_blank">Track 3: Sensor Placement</a>
            <a class="navbar-item" href="https://robosense2025.github.io/track4" target="_blank">Track 4: Cross-Modal Drone Navigation</a>
            <a class="navbar-item" href="https://robosense2025.github.io/track5" target="_blank">Track 5: Cross-Platform 3D Object Detection</a>
          </div>
        </div>
      </div>
    </div>
  </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <i class="fas fa fa-eye fa-2x" style="color: #76b900; margin-bottom: 12px;"></i>
              <br>
              The <a style="color: #ffc000;">Robo</a><a style="color: #76b900;">Sense</a> Challenge 2025
            </h1>
            <h2 class="title is-2 publication-title">
              Track <a style="color: #76b900;">#5</a>: Cross-Platform 3D Object Detection
            </h2>
          </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section" style="margin-top: 0px;">
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width left">
          <div class="content has-text-justified" style="padding-top: 0px">
            <p>
              üëã Welcome to <strong>Track <a style="color: #76b900;">#5</a>: Cross-Platform 3D Object Detection</strong> of the <a href="https://robosense2025.github.io/" target="_blank"><strong>2025 RoboSense Challenge</strong></a>!
            </p>
            <p>
            <img src="./images/track5/teaser.png" alt="Track 5 Image" class="img-hover-effect" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
            </p>
          </div>

          <hr>

          <h2 class="title is-3">üéØ Objective</h2>
          <div class="content has-text-justified" style="padding-top: 0px">
            <p style="font-size: 1rem; line-height: 1.6; color: #34495e;">
              As robotics continues to advance, LiDAR-based 3D object detection has become a focal point in both academia and industry. However, most existing datasets and methods target vehicle platforms, overlooking quadrupeds and drones.  
              This challenge, built on our benchmark, aims to:
            </p>
              <ol style="font-size: 1rem; line-height: 1.6; color: #34495e; padding-left: 1.2rem;">
                <li style="margin-bottom: 0.75rem;">
                  Build on three platforms‚Äî<strong>vehicles</strong>, <strong>drones</strong>, and <strong>quadruped robots</strong>‚Äîto foster innovations in a unified perception framework;
                </li>
                <li style="margin-bottom: 0.75rem;">
                  Bridge geometric and data distribution disparities to achieve rapid model transfer and adaptation across platforms;
                </li>
                <li>
                  Lower annotation and deployment overhead, supporting collaborative sensing for heterogeneous robot teams in urban, disaster, and indoor scenarios.
                </li>
              </ol>
          </div>

          <hr>

          <h2 class="title is-3">üóÇÔ∏è Phases & Requirements</h2>
          <div class="content has-text-justified" style="padding-top: 0px">
          
            <h4 class="title is-4">Phase 1: Vehicle ‚Üí Drone Adaptation</h4>
            <p>
              <strong>Duration:</strong> 15 June 2025 ‚Äì 15 August 2025
            </p>
            <p>
              <strong>Setup:</strong>
            </p>
            <ul>
              <li><strong>Source platform:</strong> Vehicle LiDAR scans <strong>with</strong> 3D bounding-box annotations</li>
              <li><strong>Target platform:</strong> Unlabeled Drone LiDAR scans</li>
            </ul>
            <p>
              <strong>Ranking Metric:</strong> AP@0.50 (R40) for the <strong>Car</strong> class evaluated on Drone data
            </p>
          
            <hr>
          
            <h4 class="title is-4">Phase 2: Vehicle ‚Üí Drone &amp; Quadruped Adaptation</h4>
            <p>
              <strong>Duration:</strong> 15 August 2025 ‚Äì 15 September 2025
            </p>
            <p>
              <strong>Setup:</strong>
            </p>
            <ul>
              <li><strong>Source platform:</strong> Vehicle LiDAR scans with annotations</li>
              <li><strong>Target platforms:</strong> Unlabeled Drone and Quadruped LiDAR scans</li>
            </ul>
            <p>
              <strong>Ranking Metric:</strong> Weighted score combining:
            </p>
            <ul>
              <li>AP@0.50 (R40) for the <strong>Car</strong> class</li>
              <li>AP@0.25 (R40) for the <strong>Pedestrian</strong> class</li>
            </ul>
            <p>
              (Scores computed across both Drone and Quadruped platforms.)
            </p>
          
          </div>
          

          <hr>

          <h2 class="title is-3">üöó Dataset Examples</h2>
          <div class="content has-text-justified" style="padding-top: 0px">
            <p>
              <img src="./images/track5/data_example1.png" alt="Track 5 Image" class="img-hover-effect" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
            </p>
            <p>
              <img src="./images/track5/data_example2.png" alt="Track 5 Image" class="img-hover-effect" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
            </p>
            <p>
              <img src="./images/track5/data_example3.png" alt="Track 5 Image" class="img-hover-effect" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
            </p>
          </div>

          <hr>

          <h2 class="title is-3">üõ†Ô∏è Baseline Model</h2>
          <div class="content has-text-justified" style="padding-top: 0px">
            <p>
              In this track, we adopt 
              <a href="https://arxiv.org/abs/1912.13192" target="_blank" rel="noopener noreferrer">
                <strong>PV-RCNN</strong>
              </a> 
              as the base 3D detector, and leverage 
              <a href="https://github.com/CVMI-Lab/ST3D" target="_blank" rel="noopener noreferrer">
                <strong>ST3D/++</strong>
              </a> 
              as our baseline adaptation framework. Detailed environment setup and experimental protocols can be found in the 
              <a href="https://github.com/robosense2025/track5" target="_blank" rel="noopener noreferrer">
                <strong>Track5 GitHub repository</strong>
              </a>.
            </p>
            <p>
              Beyond the provided baseline, participants are encouraged to explore alternative strategies to further boost cross-platform performance:
            </p>
            <ul>
              <li>Treat the cross-platform challenge as a domain adaptation problem by improving pseudo-label quality and fine-tuning on target-platform data.</li>
              <li>Design novel data augmentation techniques to bridge geometric and feature discrepancies across platforms.</li>
              <li>Adopt geometry-agnostic 3D detectors, such as point-based architectures, that are less sensitive to platform-specific point-cloud characteristics.</li>
            </ul>
          </div>
          

          <hr>

          <h2 class="title is-3">üìä Baseline Results</h2>
          <div class="content has-text-justified" style="padding-top: 0px">
            <h3 class="title is-3">Phase 1 Results</h3>
            <div class="table-container">
              <table class="table is-bordered is-striped is-hoverable is-fullwidth">
                <thead>
                  <tr>
                    <th>Metric</th>
                    <th>Car BEV AP0.7@40</th>
                    <th>Car 3D AP0.7@40</th>
                    <th>Car BEV AP0.5@40</th>
                    <th>Car 3D AP0.5@40</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>PVRCNN-Source</td>
                    <td>34.60</td>
                    <td>16.31</td>
                    <td>40.67</td>
                    <td style="background-color: yellow; font-weight: bold;">
                      33.70
                    </td>
                  </tr>
                  <tr>
                    <td>PVRCNN-ST3D</td>
                    <td>47.81</td>
                    <td>26.03</td>
                    <td>53.40</td>
                    <td style="background-color: yellow; font-weight: bold;">
                      46.64
                    </td>
                  </tr>
                  <tr>
                    <td>PVRCNN-ST3D++</td>
                    <td>45.96</td>
                    <td>25.37</td>
                    <td>52.65</td>
                    <td style="background-color: yellow; font-weight: bold;">
                      45.07
                    </td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>

          <hr>

          <h2 class="title is-3">üîó Resources</h2>
          <div class="content has-text-justified" style="padding-top: 0px">
            <p>
              We provide the following resources to support the development of models in this track:
            </p>
            <div class="table-container">
              <table class="table is-bordered is-striped is-hoverable is-fullwidth">
                <thead>
                  <tr>
                    <th>Resource</th>
                    <th>Link</th>
                    <th></th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>GitHub</td>
                    <td><a href="https://github.com/robosense2025/track5" target="_blank">https://github.com/robosense2025/track5</a><td>
                  </tr>
                  <tr>
                    <td>Checkpoint</td>
                    <td><a href="https://huggingface.co/datasets/robosense/datasets/tree/main/track5-cross-platform-3d-object-detection/pretrained" target="_blank">Huggingface Checkpoint</a><td>
                  </tr>
                  <tr>
                    <td>Dataset</td>
                    <td><a href="https://huggingface.co/datasets/robosense/datasets/tree/main/track5-cross-platform-3d-object-detection" target="_blank">Huggingface Dataset</a><td>
                  </tr>
                  <tr>
                    <td>Submit Server</td>
                    <td><a href="https://huggingface.co/datasets/robosense/datasets/tree/main/track5-cross-platform-3d-object-detection" target="_blank">Codabench</a><td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>

          <hr>





<!-- <h2 class="title is-3">üìñ References</h2>
<div class="content has-text-justified" style="padding-top: 0px;">
  <div style="
    max-width: 100%;
    overflow-x: auto;
    background-color: #f9f9f9;
    border-radius: 5px;
    padding: 1em;
    font-size: 0.9em;
    box-sizing: border-box;
  ">
    <pre style="
      margin: 0;
      font-family: monospace;
      white-space: pre;
      overflow-x: auto;
    ">
@article{xie2025drivebench,
  title     = {},
  author    = {},
  booktitle = {},
  year      = {2025},
  url       = {https://robosense2025.github.io}
}
    </pre>
  </div>
</div> -->




        </div>
      </div>
    </div>
  </section>



  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International</a> license.
            </p>
            <p>
              Copyright ¬© <a style="color: #ffc000;">Robo</a><a style="color: #76b900;">Sense</a> 2025 All Rights Reserved.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>


</body>

</html>